{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from keras.layers.core import Masking\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, TimeDistributed\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "from lxml import etree\n",
    "from itertools import groupby\n",
    "from gensim.models import Word2Vec\n",
    "import glob\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('labeled_flows_xml/TestbedMonJun14Flows.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName =[]\n",
    "totalSourceBytes=[]\n",
    "totalDestinationBytes=[]\n",
    "totalDestinationPackets=[]\n",
    "totalSourcePackets=[]\n",
    "sourcePayloadAsBase64=[]\n",
    "destinationPayloadAsBase64=[]\n",
    "destinationPayloadAsUTF=[]\n",
    "direction=[]\n",
    "sourceTCPFlagsDescription=[]\n",
    "destinationTCPFlagsDescription=[]\n",
    "source=[]\n",
    "protocolName=[]\n",
    "sourcePort=[]\n",
    "destination=[]\n",
    "destinationPort=[]\n",
    "startDateTime=[]\n",
    "stopDateTime=[]\n",
    "Tag=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for em in root.iter('appName'):\n",
    "    appName.append(em.text)\n",
    "for bt in root.iter('totalSourceBytes'):\n",
    "    totalSourceBytes.append(bt.text)\n",
    "for db in root.iter('totalDestinationBytes'):\n",
    "    totalDestinationBytes.append(db.text)\n",
    "for dp in root.iter('totalDestinationPackets'):\n",
    "    totalDestinationPackets.append(dp.text)\n",
    "for sp in root.iter('totalSourcePackets'):\n",
    "    totalSourcePackets.append(sp.text)\n",
    "for paybase in root.iter('sourcePayloadAsBase64'):\n",
    "    sourcePayloadAsBase64.append(paybase.text)\n",
    "for destpay in root.iter('destinationPayloadAsBase64'):\n",
    "    destinationPayloadAsBase64.append(destpay.text)\n",
    "for dr in root.iter('direction'):\n",
    "    direction.append(dr.text)\n",
    "for tcpf in root.iter('sourceTCPFlagsDescription'):\n",
    "    sourceTCPFlagsDescription.append(tcpf.text)\n",
    "for dtcpf in root.iter('destinationTCPFlagsDescription'):\n",
    "    destinationTCPFlagsDescription.append(dtcpf.text)\n",
    "for src in root.iter('source'):\n",
    "    source.append(src.text)\n",
    "for pname in root.iter('protocolName'):\n",
    "    protocolName.append(pname.text)\n",
    "for sport in root.iter('sourcePort'):\n",
    "    sourcePort.append(sport.text)\n",
    "for destntn in root.iter('destination'):\n",
    "    destination.append(destntn.text)\n",
    "for destntnp in root.iter('destinationPort'):\n",
    "    destinationPort.append(destntnp.text)\n",
    "for datet in root.iter('startDateTime'):\n",
    "    startDateTime.append(datet.text)\n",
    "for stopt in root.iter('stopDateTime'):\n",
    "    stopDateTime.append(stopt.text)\n",
    "for tag in root.iter('Tag'):\n",
    "    Tag.append(tag.text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'appName': appName,'totalSourceBytes':totalSourceBytes,'totalDestinationBytes':totalDestinationBytes,\n",
    "                   'totalDestinationPackets':totalDestinationPackets,'totalSourcePackets':totalSourcePackets,\n",
    "                   'sourcePayloadAsBase64': sourcePayloadAsBase64, 'destinationPayloadAsBase64': destinationPayloadAsBase64,\n",
    "                  'direction':direction, 'sourceTCPFlagsDescription': sourceTCPFlagsDescription, \n",
    "                   'destinationTCPFlagsDescription':destinationTCPFlagsDescription,  'source': source, 'protocolName':protocolName,\n",
    "                  'sourcePort':sourcePort, 'destination': destination,'destinationPort':destinationPort,\n",
    "                  'startDateTime':startDateTime, 'stopDateTime':stopDateTime, 'tag':Tag})\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De-dup Flows: 171350\n",
      "Creating undirected IP-dyads...\n"
     ]
    }
   ],
   "source": [
    "## Produce undirected IP-dyads and order by time\n",
    "df = df.sort_values('startDateTime')\n",
    "df['seqId'] = df['source'] + '_' + df['destination'] + '_' + df['startDateTime'].str[:13]\n",
    "df['lowPort'] = np.where(df.destinationPort <= df.sourcePort, df['destinationPort'], df['sourcePort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Keys: tag        22658\n",
      "lowPort    22658\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Build hour-IP-dyad keys and sequences\n",
    "key = df.groupby('seqId')[['tag','lowPort']].agg({\"tag\":lambda x: \"%s\" % ','.join([a for a in x]),\"lowPort\":lambda x: \"%s\" % ','.join([str(a) if int(a)<10000 else \"10000\" for a in x])})\n",
    "print(\"Unique Keys: \"+str(key.count()))\n",
    "attacks = [a.split(\",\") for a in key.tag.tolist()]\n",
    "sequences = [a.split(\",\") for a in key.lowPort.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Label Encoder...\n"
     ]
    }
   ],
   "source": [
    "# Create Label Encoder and add one to account for 0. masking\n",
    "##\n",
    "print(\"Generating Label Encoder...\")\n",
    "unique_tokens = list(set([a for b in sequences for a in b]))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_tokens)\n",
    "sequences = [le.transform(s).tolist() for s in sequences]\n",
    "sequences = [[b+1 for b in a] for a in sequences]\n",
    "\n",
    "sequence_attack = zip(attacks, sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences for model...\n"
     ]
    }
   ],
   "source": [
    "## Build sequences\n",
    "##\n",
    "print(\"Generating sequences for model...\")\n",
    "na_value = 0.\n",
    "seq_len = 10\n",
    "\n",
    "seq_index = []\n",
    "seq_x = []\n",
    "seq_y = []\n",
    "seq_attack = []\n",
    "for si, (sa, ss) in enumerate(sequence_attack):\n",
    "    prepend = [0.] * (seq_len)\n",
    "    seq =  prepend + ss\n",
    "    seqa = prepend + sa\n",
    "    for ii in range(seq_len, len(seq)):\n",
    "        subseq = seq[(ii-seq_len):(ii)]\n",
    "        vex = []\n",
    "        for ee in subseq:\n",
    "            try:\n",
    "                vex.append(ee)\n",
    "            except:\n",
    "                vex.append(na_value)\n",
    "        seq_x.append(vex)\n",
    "        seq_y.append(seq[ii])\n",
    "        seq_index.append(si)\n",
    "        seq_attack.append(seqa[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing One-hot-encoder...\n"
     ]
    }
   ],
   "source": [
    "## Make One-hot-encoder\n",
    "##\n",
    "print(\"Initializing One-hot-encoder...\")\n",
    "ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "ohe.fit(np.unique(seq_y).reshape(-1,1))\n",
    "X = np.array(seq_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for Batch Training\n",
    "##\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, batch_size, x, y, ohe):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = int(math.floor(np.shape(x)[0] / batch_size))\n",
    "        self.batch_index = [a * batch_size for a in range(0, self.n_batches)]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ohe = ohe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for bb in itertools.cycle(self.batch_index):\n",
    "            y = self.y[bb:(bb+self.batch_size)]\n",
    "            ohe_y = self.ohe.transform(y.reshape(len(y), 1))\n",
    "            yield (self.x[bb:(bb+self.batch_size),], ohe_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model...\n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 89s 267ms/step - loss: 5.9222 - acc: 0.2860\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 104s 311ms/step - loss: 5.2902 - acc: 0.3010\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 82s 245ms/step - loss: 4.9350 - acc: 0.3082\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 87s 262ms/step - loss: 4.6005 - acc: 0.3182\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 76s 227ms/step - loss: 4.2237 - acc: 0.3311\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 78s 233ms/step - loss: 3.9117 - acc: 0.3425\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 79s 235ms/step - loss: 3.6972 - acc: 0.3497\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 77s 232ms/step - loss: 3.5385 - acc: 0.3572\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 74s 220ms/step - loss: 3.4254 - acc: 0.3620\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 76s 228ms/step - loss: 3.3445 - acc: 0.3676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6cb17908>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define model\n",
    "##\n",
    "print(\"Defining model...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=100, input_dim=len(unique_tokens)+1, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(50, activation=\"relu\", return_sequences=False)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation=\"linear\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(unique_tokens), activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "training_data = BatchGenerator(512, np.asarray(X), np.asarray(seq_y), ohe)\n",
    "\n",
    "model.fit_generator(training_data.__iter__(),\n",
    "    steps_per_epoch=training_data.n_batches,\n",
    "    epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ports_dirty.hd5\")\n",
    "model = load_model(\"ports_dirty.hd5\")\n",
    "preds = model.predict_proba(X, batch_size=512)\n",
    "\n",
    "indexed_preds = zip(np.asarray(seq_index), preds, np.asarray(seq_y), np.asarray(seq_attack))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
